{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78bbf08c",
   "metadata": {},
   "source": [
    "# Evaluation and Prediction Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768517aa",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook defines our code for evaluating our neural network models on the validation dataset and making predictions on new data.\n",
    "\n",
    "It defines an evaluation function which runs the models in evaluation mode on the validation loader, compares predictions to truth labels, and returns overall accuracy. This is utilised to monitor validation performance during training.\n",
    "\n",
    "Next, a prediction function is defined to run the models on a loader and collect all predictions and corresponding labels. This can be used after training to make predictions on new data.\n",
    "\n",
    "The torch.no_grad decorator indicates these functions do not require gradient calculation since they are just doing forward passes through the models. Both functions use a loop over batches and tqdm for progress bar monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f139a1b",
   "metadata": {},
   "source": [
    "##  Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0759f9",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorator to indicate that the function does not require gradient calculations\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, epoch):\n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialise counters for correct predictions and total predictions\n",
    "    num_correct = 0\n",
    "    total_seen = 0\n",
    "\n",
    "    # Loop over all batches of data in the validation loader\n",
    "    for batch, labels in tqdm(val_loader, ascii=True, total=len(val_loader)):\n",
    "        # Forward pass: compute the model output (logits) for the current batch\n",
    "        logits = model(batch)\n",
    "        # Compute predictions by taking the class with highest logit\n",
    "        predictions = logits.argmax(dim=-1)\n",
    "        # Update number of correct predictions\n",
    "        num_correct += (predictions == labels).float().sum()\n",
    "        # Update total number of predictions\n",
    "        total_seen += logits.size(0)\n",
    "\n",
    "    # Display the validation performance after the current epoch\n",
    "    tqdm.write(\n",
    "        f\"Val Perf after {epoch + 1} epochs \"\n",
    "        f\"Acc@1 {(num_correct / total_seen):0.4f}\",\n",
    "    )\n",
    "\n",
    "    # Return the accuracy for this evaluation\n",
    "    return num_correct / total_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a39d35",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f590352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorator to indicate that the function does not require gradient calculations\n",
    "@torch.no_grad()\n",
    "def predict(model, val_loader, epoch):\n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialise lists to store all predictions and corresponding labels\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Loop over all batches of data in the validation loader\n",
    "    for batch, labels in tqdm(val_loader, ascii=True, total=len(val_loader)):\n",
    "        # Forward pass: compute the model output (logits) for the current batch\n",
    "        logits = model(batch)\n",
    "        # Compute predictions by taking the class with highest logit\n",
    "        predictions = logits.argmax(dim=-1)\n",
    "        # Append current batch's predictions and labels to their respective lists\n",
    "        all_predictions += list(predictions)\n",
    "        all_labels += list(labels)\n",
    "\n",
    "    # Return lists of all predictions and corresponding labels\n",
    "    return all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0914761",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#### Code adapted from:\n",
    "\n",
    "* https://github.com/pytorch\n",
    "* https://github.com/RAIVNLab/supsup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
