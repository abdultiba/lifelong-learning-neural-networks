{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae05fa1e",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543ecf6",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook implements Experiment 1 to analyse the extent of supermasks overlaps when training our classic model on variants of the MNIST dataset.\n",
    "\n",
    "The key components are:\n",
    "\n",
    "* **Model Training**:\n",
    "    * Implements modular network training by looping through tasks, training the MultitaskFC model and extracting supermasks.\n",
    "    * Three dataset variants are used - Permuted MNIST, Rotated MNIST and Partitioned MNIST.\n",
    "\n",
    "* **Supermask Analysis**:\n",
    "    * Calculates supermask overlaps using the Jaccard similarity index.\n",
    "    * Visually inspects supermasks patterns by plotting grids.\n",
    "    * Statistically compares supermask similarity using t-tests.\n",
    "\n",
    "* **Results Analysis**:\n",
    "    * Supermask overlaps are visualised in 3D scatter plots.\n",
    "    * Statistical comparison results are collected in DataFrames and sorted.\n",
    "    * Key observations are made about supermask patterns for each dataset variant.\n",
    "\n",
    "The notebook demonstrates our comprehensive experiment workflow for analysing and determining the extent of overlap between supermasks for different tasks - implementing training, extracting supermasks, evaluating similarities, and visualising and comparing results. The analysis provides insights into how supermasks overlap based on the nature of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa749d4f",
   "metadata": {},
   "source": [
    "##  Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44603d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utilities.train_funcs import train\n",
    "from utilities.eval_pred_funcs import evaluate\n",
    "from utilities.models import MultitaskFC, MultitaskMaskLinear\n",
    "from utilities.data import MNISTPerm, PartitionMNIST, RotatingMNIST\n",
    "from utilities.similarity_funcs import jaccard_index, plot_supermask\n",
    "from utilities.utils import cache_masks, set_model_task, set_num_tasks_learned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fca3e6",
   "metadata": {},
   "source": [
    "## Permuted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c704e78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load permuted MNIST dataset\n",
    "mnist = MNISTPerm()\n",
    "\n",
    "# Set the number of tasks\n",
    "num_tasks = 2\n",
    "\n",
    "# Initialise the MultitaskFC model for the tasks\n",
    "model = MultitaskFC(hidden_size=300, num_tasks=num_tasks)\n",
    "\n",
    "# Initialise a list to store supermasks for each task\n",
    "supermasks_perm = []\n",
    "\n",
    "# Loop through each task for training and evaluation\n",
    "for task_id in range(num_tasks):\n",
    "    print(f\"Training for task {task_id}\")\n",
    "    \n",
    "    # Set the current task in the model\n",
    "    set_model_task(model, task_id)\n",
    "    \n",
    "    # Update the task in the dataset\n",
    "    mnist.update_task(task_id)\n",
    "    \n",
    "    # Initialise the optimiser (RMSprop) for model parameters that require gradient computation\n",
    "    optimizer = optim.RMSprop([p for p in model.parameters() if p.requires_grad], lr=1e-4)\n",
    "    \n",
    "    # Loop over each epoch to train the model\n",
    "    for e in range(1):\n",
    "        # Use the training function for this model\n",
    "        train(model, mnist.train_loader, optimizer, e, task_id)\n",
    "        \n",
    "        # Display validation information\n",
    "        print(\"Validation\")\n",
    "        print(\"============\")\n",
    "        \n",
    "        # Evaluate the model's performance on the validation dataset\n",
    "        acc1 = evaluate(model, mnist.val_loader, e)\n",
    "\n",
    "    # Retrieve and store the supermasks for this task\n",
    "    masks_for_current_task = model.get_masks(layer_index=3)\n",
    "    \n",
    "    # Append the mask corresponding to the current task ID to the supermasks_perm list\n",
    "    supermasks_perm.append(masks_for_current_task[task_id])\n",
    "    \n",
    "    # Cache the current state of the masks in the model\n",
    "    cache_masks(model)\n",
    "    print()\n",
    "    \n",
    "    # Update the number of learned tasks in the model\n",
    "    set_num_tasks_learned(model, task_id + 1)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b5d474",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialise a list to store data about overlap between supermasks\n",
    "data = []\n",
    "\n",
    "# Loop over each task\n",
    "for i in range(num_tasks):\n",
    "    # Loop over each task again to compare each pair of tasks\n",
    "    for j in range(num_tasks):\n",
    "        # Skip comparison of the same task with itself\n",
    "        if i == j:\n",
    "            continue\n",
    "        \n",
    "        # Convert supermasks from tensor format to numpy array format\n",
    "        supermask1 = supermasks_perm[i].detach().numpy()\n",
    "        supermask2 = supermasks_perm[j].detach().numpy()\n",
    "        \n",
    "        # Compute the Jaccard index between the two supermasks \n",
    "        # and round the result to two decimal places after multiplying by 100 to get a percentage\n",
    "        overlap = round(jaccard_index(supermask1, supermask2) * 100, 2)\n",
    "\n",
    "        # Append the task IDs and their overlap percentage to the data list\n",
    "        data.append([i, j, overlap])\n",
    "        \n",
    "        # Print out the tasks being compared and their overlap percentage\n",
    "        print(f\"Task: {i}, Task: {j}, Overlap: {overlap}%\")\n",
    "\n",
    "# Convert the collected data into a DataFrame with appropriate column names\n",
    "df = pd.DataFrame(data, columns=[\"supermask1\", \"supermask2\", \"overlap\"])\n",
    "\n",
    "# Initialise a 3D plotting figure\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the data points in 3D plot\n",
    "ax.scatter(df['supermask1'], df['supermask2'], df['overlap'])\n",
    "ax.set_xlabel('Supermask (Task ID)')\n",
    "ax.set_ylabel('Supermask (Task ID)')\n",
    "ax.set_zlabel('Overlap (%)')\n",
    "\n",
    "# Set the title for the plot\n",
    "plt.title('Jaccard Index Overlap - MNIST Permuted')\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('figures/perm_supermasks_overlap_jac_index.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034c3e5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the total number of tasks from the length of the supermasks_perm list\n",
    "num_tasks = len(supermasks_perm)\n",
    "\n",
    "# Create a grid of subplots with 5 rows and 2 columns, and define the figure size\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8, 20))\n",
    "\n",
    "# Loop through each supermask in the supermasks_perm list\n",
    "for i, supermask in enumerate(supermasks_perm):\n",
    "    # Determine the row number for plotting based on the current index\n",
    "    row = i % 5\n",
    "    # Determine the column number for plotting based on the current index\n",
    "    col = i // 5\n",
    "    # Plot the supermask on the respective subplot\n",
    "    plot_supermask(axes[row][col], supermask.detach().numpy(), i)\n",
    "\n",
    "# Adjust the layout of the plots for better visualisation and to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the entire grid of plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f234598e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert each supermask in the supermasks_perm list from tensor to numpy format\n",
    "all_supermasks = [mask.detach().numpy() for mask in supermasks_perm]\n",
    "\n",
    "# Convert the list of supermasks into a numpy array for indexing and manipulation\n",
    "all_supermasks = np.array(all_supermasks)\n",
    "\n",
    "# Define a function to statistically compare two tasks based on their supermasks\n",
    "def compare_tasks_statistically(task1, task2):\n",
    "    # Flatten the supermasks for the two tasks to make them 1D arrays\n",
    "    data1 = all_supermasks[task1].flatten()\n",
    "    data2 = all_supermasks[task2].flatten()\n",
    "    \n",
    "    # Compute the t-statistic and p-value using a two-sample t-test to compare the two tasks\n",
    "    t_stat, p_value = ttest_ind(data1, data2)\n",
    "    \n",
    "    # Return the results in a dictionary format\n",
    "    return {\"Task Pair\": (task1, task2), \"t-statistic\": t_stat, \"p-value\": p_value}\n",
    "\n",
    "# Initialise a list to store comparison results between tasks\n",
    "results = []\n",
    "\n",
    "# Loop through each unique pair of tasks\n",
    "for i in range(len(all_supermasks)):\n",
    "    for j in range(i+1, len(all_supermasks)):\n",
    "        # Compare the tasks statistically and store the results\n",
    "        result = compare_tasks_statistically(i, j)\n",
    "        \n",
    "        # Append the results to the results list\n",
    "        results.append(result)\n",
    "\n",
    "# Convert the list of comparison results into a DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Print the entire DataFrame without row indices\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Sort the DataFrame by p-values in descending order (higher p-values indicate greater similarity) and reset its index\n",
    "df_sorted_similarity = df_results.sort_values(by='p-value', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print the sorted DataFrame without row indices\n",
    "print(df_sorted_similarity.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355aa1b",
   "metadata": {},
   "source": [
    "## Rotated MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rotated MNIST dataset\n",
    "mnist = RotatingMNIST()\n",
    "\n",
    "# Set the number of tasks\n",
    "num_tasks = 10\n",
    "\n",
    "# Initialise the MultitaskFC model for the tasks\n",
    "model = MultitaskFC(hidden_size=300, num_tasks=num_tasks)\n",
    "\n",
    "# Initialise a list to store supermasks for each task\n",
    "supermasks_rotate = []\n",
    "\n",
    "# Loop through each task for training and evaluation\n",
    "for task_id in range(num_tasks):\n",
    "    print(f\"Training for task {task_id}\")\n",
    "    \n",
    "    # Set the current task in the model\n",
    "    set_model_task(model, task_id)\n",
    "    \n",
    "    # Update the task in the dataset\n",
    "    mnist.update_task(task_id)\n",
    "    \n",
    "    # Initialise the optimiser (RMSprop) for model parameters that require gradient computation\n",
    "    optimizer = optim.RMSprop([p for p in model.parameters() if p.requires_grad], lr=1e-4)\n",
    "    \n",
    "    # Loop over each epoch to train the model\n",
    "    for e in range(1):\n",
    "        # Use the training function for this model\n",
    "        train(model, mnist.train_loader, optimizer, e, task_id)\n",
    "        \n",
    "        # Display validation information\n",
    "        print(\"Validation\")\n",
    "        print(\"============\")\n",
    "        \n",
    "        # Evaluate the model's performance on the validation dataset\n",
    "        acc1 = evaluate(model, mnist.val_loader, e)\n",
    "\n",
    "    # Retrieve and store the supermasks for this task\n",
    "    masks_for_current_task = model.get_masks(layer_index=3)\n",
    "    \n",
    "    # Append the mask corresponding to the current task ID to the supermasks_rotate list\n",
    "    supermasks_rotate.append(masks_for_current_task[task_id])\n",
    "    \n",
    "    # Cache the current state of the masks in the model\n",
    "    cache_masks(model)\n",
    "    print()\n",
    "    \n",
    "    # Update the number of learned tasks in the model\n",
    "    set_num_tasks_learned(model, task_id + 1)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b77a280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialise a list to store data about overlap between supermasks\n",
    "data = []\n",
    "\n",
    "# Loop over each task\n",
    "for i in range(num_tasks):\n",
    "    # Loop over each task again to compare each pair of tasks\n",
    "    for j in range(num_tasks):\n",
    "        # Skip comparison of the same task with itself\n",
    "        if i == j:\n",
    "            continue\n",
    "            \n",
    "        # Convert supermasks from tensor format to numpy array format\n",
    "        supermask1 = supermasks_rotate[i].detach().numpy()\n",
    "        supermask2 = supermasks_rotate[j].detach().numpy()\n",
    "        \n",
    "        # Compute the Jaccard index between the two supermasks \n",
    "        # and round the result to two decimal places after multiplying by 100 to get a percentage\n",
    "        overlap = round(jaccard_index(supermask1, supermask2) * 100, 2)\n",
    "        \n",
    "        # Append the task IDs and their overlap percentage to the data list\n",
    "        data.append([i, j, overlap])\n",
    "        \n",
    "        # Print out the tasks being compared and their overlap percentage\n",
    "        print(f\"Task: {i}, Task: {j}, Overlap: {overlap}%\")\n",
    "        \n",
    "# Convert the collected data into a DataFrame with appropriate column names\n",
    "df = pd.DataFrame(data, columns=[\"supermask1\", \"supermask2\", \"overlap\"])\n",
    "\n",
    "# Initialise a 3D plotting figure\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the data points in 3D plot\n",
    "ax.scatter(df['supermask1'], df['supermask2'], df['overlap'])\n",
    "ax.set_xlabel('Supermask (Task ID)')\n",
    "ax.set_ylabel('Supermask (Task ID)')\n",
    "ax.set_zlabel('Overlap (%)')\n",
    "\n",
    "# Set the title for the plot\n",
    "plt.title('Jaccard Index Overlap - MNIST Rotated')\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('figures/rotate_supermasks_overlap_jac_index.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f9193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the total number of tasks from the length of the supermasks_rotate list\n",
    "num_tasks = len(supermasks_rotate)\n",
    "\n",
    "# Create a grid of subplots with 5 rows and 2 columns, and define the figure size\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8, 20))\n",
    "\n",
    "# Loop through each supermask in the supermasks_rotate list\n",
    "for i, supermask in enumerate(supermasks_rotate):\n",
    "    # Determine the row number for plotting based on the current index\n",
    "    row = i % 5\n",
    "    # Determine the column number for plotting based on the current index\n",
    "    col = i // 5\n",
    "    # Plot the supermask on the respective subplot\n",
    "    plot_supermask(axes[row][col], supermask.detach().numpy(), i)\n",
    "    \n",
    "# Adjust the layout of the plots for better visualisation and to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the entire grid of plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584e2e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert each supermask in the supermasks_rotate list from tensor to numpy format\n",
    "all_supermasks = [mask.detach().numpy() for mask in supermasks_rotate]\n",
    "\n",
    "# Convert the list of supermasks into a numpy array for indexing and manipulation\n",
    "all_supermasks = np.array(all_supermasks)\n",
    "\n",
    "# Initialise a list to store comparison results between tasks\n",
    "results = []\n",
    "\n",
    "# Loop through each unique pair of tasks\n",
    "for i in range(len(all_supermasks)):\n",
    "    for j in range(i+1, len(all_supermasks)):\n",
    "        # Compare the tasks statistically and store the results\n",
    "        result = compare_tasks_statistically(i, j)\n",
    "        \n",
    "        # Append the results to the results list\n",
    "        results.append(result)\n",
    "        \n",
    "# Convert the list of comparison results into a DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Print the entire DataFrame without row indices\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Sort the DataFrame by p-values in descending order (higher p-values indicate greater similarity) and reset its index\n",
    "df_sorted_similarity = df_results.sort_values(by='p-value', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print the sorted DataFrame without row indices\n",
    "print(df_sorted_similarity.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ad9df",
   "metadata": {},
   "source": [
    "## Partitioned MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17827ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load partitioned MNIST dataset\n",
    "mnist = PartitionMNIST()\n",
    "\n",
    "# Set the number of tasks\n",
    "num_tasks = 10\n",
    "\n",
    "# Initialise the MultitaskFC model for the tasks\n",
    "model = MultitaskFC(hidden_size=300, num_tasks=num_tasks)\n",
    "\n",
    "# Initialise a list to store supermasks for each task\n",
    "supermasks_part = []\n",
    "\n",
    "# Loop through each task for training and evaluation\n",
    "for task_id in range(num_tasks):\n",
    "    print(f\"Training for task {task_id}\")\n",
    "    \n",
    "    # Set the current task in the model\n",
    "    set_model_task(model, task_id)\n",
    "    \n",
    "    # Update the task in the dataset\n",
    "    mnist.update_task(task_id)\n",
    "    \n",
    "    # Initialise the optimiser (RMSprop) for model parameters that require gradient computation\n",
    "    optimizer = optim.RMSprop([p for p in model.parameters() if p.requires_grad], lr=1e-4)\n",
    "    \n",
    "    # Loop over each epoch to train the model\n",
    "    for e in range(1):\n",
    "        # Use the training function for this model\n",
    "        train(model, mnist.train_loader, optimizer, e, task_id)\n",
    "        \n",
    "         # Display validation information\n",
    "        print(\"Validation\")\n",
    "        print(\"============\")\n",
    "        \n",
    "        # Evaluate the model's performance on the validation dataset\n",
    "        acc1 = evaluate(model, mnist.val_loader, e)\n",
    "    \n",
    "    # Retrieve and store the supermasks for this task\n",
    "    masks_for_current_task = model.get_masks(layer_index=3)\n",
    "    \n",
    "    # Append the mask corresponding to the current task ID to the supermasks_part list\n",
    "    supermasks_part.append(masks_for_current_task[task_id])\n",
    "    \n",
    "    # Cache the current state of the masks in the model\n",
    "    cache_masks(model)\n",
    "    print()\n",
    "    \n",
    "    # Update the number of learned tasks in the model\n",
    "    set_num_tasks_learned(model, task_id + 1)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca3ceb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialise a list to store data about overlap between supermasks\n",
    "data = []\n",
    "\n",
    "# Loop over each task\n",
    "for i in range(num_tasks):\n",
    "    # Loop over each task again to compare each pair of tasks\n",
    "    for j in range(num_tasks):\n",
    "        # Skip comparison of the same task with itself\n",
    "        if i == j:\n",
    "            continue\n",
    "            \n",
    "        # Convert supermasks from tensor format to numpy array format\n",
    "        supermask1 = supermasks_part[i].detach().numpy()\n",
    "        supermask2 = supermasks_part[j].detach().numpy()\n",
    "        \n",
    "        # Compute the Jaccard index between the two supermasks \n",
    "        # and round the result to two decimal places after multiplying by 100 to get a percentage\n",
    "        overlap = round(jaccard_index(supermask1, supermask2) * 100, 2)\n",
    "        \n",
    "        # Append the task IDs and their overlap percentage to the data list\n",
    "        data.append([i, j, overlap])\n",
    "        \n",
    "        # Print out the tasks being compared and their overlap percentage\n",
    "        print(f\"Task: {i}, Task: {j}, Overlap: {overlap}%\")\n",
    "\n",
    "# Convert the collected data into a DataFrame with appropriate column names\n",
    "df = pd.DataFrame(data, columns=[\"supermask1\", \"supermask2\", \"overlap\"])\n",
    "\n",
    "# Initialise a 3D plotting figure\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the data points in 3D plot\n",
    "ax.scatter(df['supermask1'], df['supermask2'], df['overlap'])\n",
    "ax.set_xlabel('Supermask (Task ID)')\n",
    "ax.set_ylabel('Supermask (Task ID)')\n",
    "ax.set_zlabel('Overlap (%)')\n",
    "\n",
    "# Set the title for the plot\n",
    "plt.title('Jaccard Index Overlap - MNIST Partitioned')\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('figures/part_supermasks_overlap_jac_index.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f27de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the total number of tasks from the length of the supermasks_part list\n",
    "num_tasks = len(supermasks_part)\n",
    "\n",
    "# Create a grid of subplots with 5 rows and 2 columns, and define the figure size\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8, 20))\n",
    "\n",
    "# Loop through each supermask in the supermasks_part list\n",
    "for i, supermask in enumerate(supermasks_part):\n",
    "    # Determine the row number for plotting based on the current index\n",
    "    row = i % 5\n",
    "    # Determine the column number for plotting based on the current index\n",
    "    col = i // 5\n",
    "    # Plot the supermask on the respective subplot\n",
    "    plot_supermask(axes[row][col], supermask.detach().numpy(), i)\n",
    "\n",
    "# Adjust the layout of the plots for better visualisation and to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the entire grid of plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061be6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each supermask in the supermasks_part list from tensor to numpy format\n",
    "all_supermasks = [mask.detach().numpy() for mask in supermasks_part]\n",
    "\n",
    "# Convert the list of supermasks into a numpy array for indexing and manipulation\n",
    "all_supermasks = np.array(all_supermasks)\n",
    "\n",
    "# Initialise a list to store comparison results between tasks\n",
    "results = []\n",
    "\n",
    "# Loop through each unique pair of tasks\n",
    "for i in range(len(all_supermasks)):\n",
    "    for j in range(i+1, len(all_supermasks)):\n",
    "        # Compare the tasks statistically and store the results\n",
    "        result = compare_tasks_statistically(i, j)\n",
    "        \n",
    "        # Append the results to the results list\n",
    "        results.append(result)\n",
    "\n",
    "# Convert the list of comparison results into a DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Print the entire DataFrame without row indices\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Sort the DataFrame by p-values in descending order (higher p-values indicate greater similarity) and reset its index\n",
    "df_sorted_similarity = df_results.sort_values(by='p-value', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print the sorted DataFrame without row indices\n",
    "print(df_sorted_similarity.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551c316",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#### Code adapted from:\n",
    "\n",
    "* https://github.com/pytorch\n",
    "* https://github.com/RAIVNLab/supsup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
