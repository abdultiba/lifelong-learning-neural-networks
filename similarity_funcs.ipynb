{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5940d0",
   "metadata": {},
   "source": [
    "# Supermask Overlap and Task Similarity Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b76eb5",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook implements several functions to analyse the similarity between neural network activations for different tasks and determine importance scores.\n",
    "\n",
    "The key functions are:\n",
    "\n",
    "* **jaccard_index**: Calculates the Jaccard similarity index between two supermasks. This measures the overlap between the supermasks.\n",
    "* **plot_supermask**: Visualises the supermasks' neural activity on a plot.\n",
    "* **calculate_task_similarityE1**: Computes the cosine similarity between the batch normalisation layer means for two tasks in the classic approach. This gives a measure of supermask overlap or task similarity.\n",
    "* **calculate_task_similarityE2**: Compute similarities for multiple layers and return a dictionary with similarity matrices for each layer in the novel approach.\n",
    "* **determine_alphas**: Uses the task similarity matrices to determine alpha values per layer for a given task in the novel approach. The alpha values indicate how much the most similar prior task should influence the training of the current task.\n",
    "\n",
    "The similarity analysis enables us to quantify how related different tasks are based on the neural activations. Plotting the supermasks also provides a visual depiction of the neural representations. The alpha values are then used and set for training the novel approach. \n",
    "\n",
    "This notebook implements several valuable functions for analysing and visualising neural network dynamics for continual learning across multiple tasks. The similarity analysis and alpha calculation, in particular, provide critical insights into mask overlap for different tasks and inform the training procedure of the novel approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d20fde",
   "metadata": {},
   "source": [
    "##  Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb414c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2e1954",
   "metadata": {},
   "source": [
    "## Classic Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df859b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(supermask1, supermask2):\n",
    "    # Calculate the intersection (count of positions where both supermasks have a value of 1)\n",
    "    intersection = np.sum(np.logical_and(supermask1, supermask2))\n",
    "    \n",
    "    # Calculate the union (count of positions where at least one supermask has a value of 1)\n",
    "    union = np.sum(np.logical_or(supermask1, supermask2))\n",
    "    \n",
    "    # Compute the Jaccard index\n",
    "    jaccard = intersection / union if union != 0 else 0\n",
    "    \n",
    "    return jaccard\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_supermask(ax, supermask, task_id):\n",
    "    # Display the supermask on the given axis using a reverse grayscale colormap\n",
    "    im = ax.imshow(supermask, cmap=\"gray_r\")\n",
    "    \n",
    "    # Set title and axis labels\n",
    "    ax.set_title(f\"Neural Activity for Task {task_id}\")\n",
    "    ax.set_xlabel(\"Neuron Index\")\n",
    "    ax.set_ylabel(\"Neuron Index\")\n",
    "    \n",
    "    # Create space for the colourbar on the right of the plot\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    \n",
    "    # Attach the colourbar\n",
    "    plt.colorbar(im, cax=cax)\n",
    "    \n",
    "    plt.savefig('figures/perm_neural_acitivity.png', bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def calculate_task_similarityE1(bn_means_dict, num_tasks):\n",
    "    \n",
    "    # Initialise a similarity matrix with zeros\n",
    "    similarities_matrix = np.zeros((num_tasks, num_tasks))\n",
    "    \n",
    "    # Loop through each task\n",
    "    for task_id in range(num_tasks):\n",
    "        \n",
    "        # Retrieve the mean dictionary for the current task\n",
    "        current_task_mean_dict = bn_means_dict[task_id]\n",
    "        \n",
    "        # Skip the current task if the mean dictionary is None or does not contain index 1\n",
    "        if current_task_mean_dict is None or 1 not in current_task_mean_dict:\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        # Get the mean from the first batch normalisation layer\n",
    "        current_task_mean = current_task_mean_dict[1]\n",
    "        \n",
    "        # Convert mean to numpy array\n",
    "        current_task_mean_numpy = current_task_mean.cpu().numpy().reshape(1, -1)\n",
    "        \n",
    "        # Iterate through the mean dictionaries for all tasks\n",
    "        for i, mean_dict in enumerate(bn_means_dict.values()):\n",
    "            \n",
    "            # If mean dictionary exists and contains index 1\n",
    "            if mean_dict is not None and 1 in mean_dict:\n",
    "                \n",
    "                # Retrieve the mean for the first batch normalisation layer\n",
    "                mean = mean_dict[1]\n",
    "                \n",
    "                # Convert mean to numpy array\n",
    "                mean_numpy = mean.cpu().numpy().reshape(1, -1)\n",
    "                \n",
    "                # Calculate cosine similarity\n",
    "                similarity = cosine_similarity(current_task_mean_numpy, mean_numpy)\n",
    "                \n",
    "                # Get absolute value\n",
    "                similarity_value = abs(similarity[0][0]) if isinstance(similarity, np.ndarray) else abs(similarity)\n",
    "                \n",
    "                # Assign the similarity value to the matrix\n",
    "                similarities_matrix[task_id, i] = similarity_value\n",
    "                \n",
    "    # Return the similarities matrix\n",
    "    return similarities_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e1b03",
   "metadata": {},
   "source": [
    "## Novel Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eeee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_task_similarityE2(bn_means_dict, num_tasks):\n",
    "    \n",
    "    # Dictionary to store similarities per layer\n",
    "    layer_similarities = {}\n",
    "    \n",
    "    # Check if the mean dictionary for task 0 is not None before accessing keys\n",
    "    if bn_means_dict[0] is not None:\n",
    "        \n",
    "        # Iterate through each layer index in the mean dictionary\n",
    "        for layer_index in bn_means_dict[0].keys():\n",
    "            \n",
    "            # Initialise a similarity matrix with zeros\n",
    "            similarities_matrix = np.zeros((num_tasks, num_tasks))\n",
    "            \n",
    "            # Loop through each task\n",
    "            for task_id in range(num_tasks):\n",
    "                \n",
    "                # Retrieve the mean dictionary for the current task\n",
    "                current_task_mean = bn_means_dict[task_id]\n",
    "                \n",
    "                # If the mean dictionary exists\n",
    "                if current_task_mean is not None:\n",
    "                    \n",
    "                    # Retrieve and convert the mean for the current layer to numpy array\n",
    "                    current_task_mean_numpy = current_task_mean[layer_index].cpu().numpy().reshape(1, -1)\n",
    "                    \n",
    "                    # Iterate through the means for all tasks\n",
    "                    for i, mean in enumerate(bn_means_dict.values()):\n",
    "                        \n",
    "                        # If mean dictionary and the mean for the current layer exist\n",
    "                        if mean is not None and mean[layer_index] is not None:\n",
    "                            \n",
    "                            # Convert the mean for the current layer to numpy array\n",
    "                            mean_numpy = mean[layer_index].cpu().numpy().reshape(1, -1)\n",
    "                            \n",
    "                            # Calculate cosine similarity\n",
    "                            similarity = cosine_similarity(current_task_mean_numpy, mean_numpy)\n",
    "                            \n",
    "                            # Get absolute value of similarity\n",
    "                            similarity_value = abs(similarity[0][0]) if isinstance(similarity, np.ndarray) else abs(similarity)\n",
    "                            \n",
    "                            # Assign the similarity value to the matrix\n",
    "                            similarities_matrix[task_id, i] = similarity_value\n",
    "                            \n",
    "            # Store the similarities matrix for the current layer\n",
    "            layer_similarities[layer_index] = similarities_matrix\n",
    "            \n",
    "    # Return the dictionary containing similarities per layer\n",
    "    return layer_similarities\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def determine_alphas(similarities, current_task):\n",
    "    \n",
    "    # Dictionary to store alpha values per layer\n",
    "    alphas_per_layer = {}\n",
    "    \n",
    "    # Iterate through each layer index and corresponding similarity matrix\n",
    "    for layer_index, layer_similarity in similarities.items():\n",
    "        \n",
    "        # Retrieve similarities for the current task\n",
    "        task_similarities = layer_similarity[current_task]\n",
    "        \n",
    "        # Create zeros array of the same shape as similarities\n",
    "        alphas = np.zeros_like(task_similarities)\n",
    "        \n",
    "        # Find the index of the most similar task\n",
    "        most_similar_task = np.argmax(task_similarities)\n",
    "        \n",
    "        # Set alpha for the most similar task to 1\n",
    "        alphas[most_similar_task] = 1\n",
    "        \n",
    "        # Convert alphas to a tensor\n",
    "        alphas_per_layer[layer_index] = torch.tensor(alphas, dtype=torch.float)\n",
    "        \n",
    "    # Return the dictionary containing alphas per layer\n",
    "    return alphas_per_layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
